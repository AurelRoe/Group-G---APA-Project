{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ff167f9b",
      "metadata": {
        "id": "ff167f9b"
      },
      "source": [
        "# File with both models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1itHBsJg5VBV",
      "metadata": {
        "id": "1itHBsJg5VBV"
      },
      "outputs": [],
      "source": [
        "from keras.saving import register_keras_serializable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0045a3",
      "metadata": {
        "id": "bb0045a3"
      },
      "source": [
        "# Binary Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "06b49119",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06b49119",
        "outputId": "0df6bb22-c902-4c05-b89f-db391d031572"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.5234 - loss: 0.6918 - val_accuracy: 0.6834 - val_loss: 0.6648\n",
            "Epoch 2/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - accuracy: 0.6736 - loss: 0.6368 - val_accuracy: 0.7264 - val_loss: 0.5541\n",
            "Epoch 3/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.7570 - loss: 0.5184 - val_accuracy: 0.8054 - val_loss: 0.4425\n",
            "Epoch 4/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 80ms/step - accuracy: 0.8252 - loss: 0.4053 - val_accuracy: 0.8472 - val_loss: 0.3682\n",
            "Epoch 5/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 155ms/step - accuracy: 0.8642 - loss: 0.3319 - val_accuracy: 0.8650 - val_loss: 0.3209\n",
            "Epoch 6/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.8997 - loss: 0.2652 - val_accuracy: 0.8808 - val_loss: 0.2907\n",
            "Epoch 7/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 74ms/step - accuracy: 0.9194 - loss: 0.2163 - val_accuracy: 0.8900 - val_loss: 0.2732\n",
            "Epoch 8/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 118ms/step - accuracy: 0.9458 - loss: 0.1697 - val_accuracy: 0.8964 - val_loss: 0.2629\n",
            "Epoch 9/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 164ms/step - accuracy: 0.9566 - loss: 0.1420 - val_accuracy: 0.8990 - val_loss: 0.2587\n",
            "Epoch 10/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 110ms/step - accuracy: 0.9717 - loss: 0.1109 - val_accuracy: 0.8988 - val_loss: 0.2604\n",
            "Epoch 11/20\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.9781 - loss: 0.0891 - val_accuracy: 0.8988 - val_loss: 0.2611\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8893 - loss: 0.2665\n",
            "Test Accuracy: 0.8913\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step\n",
            "F1 Score: 0.8921\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# Load IMDB data\n",
        "max_features = 5000  # Vocabulary size\n",
        "maxlen = 500         # Maximum sequence length\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Build the model\n",
        "model_bin = keras.Sequential([\n",
        " layers.Embedding(input_dim=max_features, output_dim=128, input_length=maxlen),\n",
        "    layers.Conv1D(filters=128, kernel_size=5, activation='relu', padding='same'),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model_bin.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "history = model_bin.fit(x_train, y_train,\n",
        "                    epochs=20, # Added 10 epochs\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model_bin.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Plot training & validation accuracy and loss\n",
        "history_dict = history.history\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "\n",
        "#Soruce: https://bagheri365.github.io/blog/Sentiment-Analysis-of-IMDB-Movie-Reviews-using-Convolutional-Neural-Network-%28CNN%29-with-Hyperparameters-Tuning/?utm_source=chatgpt.com\n",
        "\n",
        "\n",
        "## SCORES\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_prob = model_bin.predict(x_test)\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "# Compute F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4746a39e",
      "metadata": {
        "id": "4746a39e"
      },
      "source": [
        "# Multiclass Model - Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6a9c9c90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a9c9c90",
        "outputId": "4878b5fb-20b3-401f-dca8-956bdf2bb560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, Conv1D\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b9a17be0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9a17be0",
        "outputId": "052de742-4315-4e71-d7e8-9f0ac7108b07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying gs://gresearch/goemotions/data/full_dataset/goemotions_1.csv...\n",
            "/ [0 files][    0.0 B/ 13.5 MiB]                                                \n",
            "/ [0 files][320.0 KiB/ 13.5 MiB]                                                \n",
            "-\n",
            "- [1 files][ 13.5 MiB/ 13.5 MiB]                                                \n",
            "Copying gs://gresearch/goemotions/data/full_dataset/goemotions_2.csv...\n",
            "- [1 files][ 13.5 MiB/ 27.0 MiB]                                                \n",
            "\\\n",
            "\\ [1 files][ 17.3 MiB/ 27.0 MiB]                                                \n",
            "\\ [2 files][ 27.0 MiB/ 27.0 MiB]                                                \n",
            "Copying gs://gresearch/goemotions/data/full_dataset/goemotions_3.csv...\n",
            "\\ [2 files][ 27.0 MiB/ 40.8 MiB]                                                \n",
            "\\ [2 files][ 27.4 MiB/ 40.8 MiB]                                                \n",
            "|\n",
            "/\n",
            "/ [3 files][ 40.8 MiB/ 40.8 MiB]                                                \n",
            "\n",
            "Operation completed over 3 objects/40.8 MiB.                                     \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "#Download the goemotions dataset\n",
        "!gsutil cp -r gs://gresearch/goemotions/data/full_dataset/ .\n",
        "\n",
        "# Load the CSV files\n",
        "df1 = pd.read_csv(\"full_dataset/goemotions_1.csv\")\n",
        "df2 = pd.read_csv(\"full_dataset/goemotions_2.csv\")\n",
        "df3 = pd.read_csv(\"full_dataset/goemotions_3.csv\")\n",
        "\n",
        "# Concatenate them into one dataframe\n",
        "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "# To reduce the runtime we use a random sample of 50.000 datapoints\n",
        "df_small = df.sample(n=50000, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "462ab5f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462ab5f8",
        "outputId": "b6371d12-2ba0-4e84-f7e0-cb1f0cb3ab17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of emotion labels: 28\n",
            "Emotion labels: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
            "Vocabulary Size: 23655\n",
            "Padded Training Data Shape: (40000, 100)\n"
          ]
        }
      ],
      "source": [
        "# Identify emotion columns\n",
        "emotion_columns = df_small.columns[df_small.columns.get_loc('example_very_unclear') + 1:].tolist()\n",
        "print(f\"Number of emotion labels: {len(emotion_columns)}\")\n",
        "print(f\"Emotion labels: {emotion_columns}\")\n",
        "\n",
        "# Data Preprocessing\n",
        "# Define features and target\n",
        "X = df_small['text']\n",
        "y = df_small[emotion_columns].values\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the text data\n",
        "max_words = 10000  # Max vocabulary size\n",
        "max_len = 100  # Max sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>') #any word that exceeds the worklimit will be set by that oov token.\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "print(f\"Vocabulary Size: {len(tokenizer.word_index)}\")\n",
        "print(f\"Padded Training Data Shape: {X_train_pad.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cbcf9cfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbcf9cfb",
        "outputId": "8c9dbf2c-e3de-40b7-8c09-0f9fb0b3dbbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: {0: np.float64(0.4293872643737387), 1: np.float64(0.7963051441312311), 2: np.float64(0.934317481080071), 3: np.float64(0.5597850425436632), 4: np.float64(0.4411894467484338), 5: np.float64(1.3190871916633689), 6: np.float64(1.0299721907508497), 7: np.float64(0.7785130400934216), 8: np.float64(1.9786307874950535), 9: np.float64(0.9070294784580499), 10: np.float64(0.6580246101204185), 11: np.float64(1.3950892857142858), 12: np.float64(2.886002886002886), 13: np.float64(1.3605442176870748), 14: np.float64(2.4461839530332683), 15: np.float64(0.6586313640255549), 16: 10.0, 17: np.float64(0.9523809523809523), 18: np.float64(0.9404683532399135), 19: np.float64(4.214075010535187), 20: np.float64(0.833472245374229), 21: np.float64(5.2521008403361344), 22: np.float64(0.8689607229753216), 23: np.float64(5.668934240362812), 24: np.float64(3.007518796992481), 25: np.float64(1.1690437222352117), 26: np.float64(1.411631846414455), 27: np.float64(0.13487268018990073)}\n"
          ]
        }
      ],
      "source": [
        "class_counts = np.sum(y_train, axis=0)\n",
        "total_samples = len(y_train)\n",
        "class_weights = {}\n",
        "for i in range(len(emotion_columns)):\n",
        "    # Calculate weight as inverse of class frequency, normalized\n",
        "    weight = total_samples / (len(emotion_columns) * class_counts[i])\n",
        "    class_weights[i] = min(weight, 10.0)  # Cap the weight to prevent extreme values\n",
        "\n",
        "print(\"Class weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06e146ea",
      "metadata": {
        "id": "06e146ea"
      },
      "source": [
        "# Defining Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2401a027",
      "metadata": {
        "id": "2401a027"
      },
      "outputs": [],
      "source": [
        "@register_keras_serializable()\n",
        "def focal_loss_with_penalty(y_true, y_pred, gamma=2.0, alpha=0.25, epsilon=1e-7):\n",
        "    # Focal loss for multi-label classification\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
        "    cross_entropy = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)\n",
        "\n",
        "    p_t = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "    focal_loss = alpha * tf.pow(1 - p_t, gamma) * cross_entropy\n",
        "\n",
        "    # Add penalty for all-zero predictions\n",
        "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
        "    all_zero_penalty = 5.0 * tf.exp(-sum_pred)  # Penalty increases as sum approaches zero\n",
        "\n",
        "    return tf.reduce_mean(focal_loss) + tf.reduce_mean(all_zero_penalty)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42e3dea",
      "metadata": {
        "id": "f42e3dea"
      },
      "source": [
        "# Define F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f9b138e7",
      "metadata": {
        "id": "f9b138e7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Custom F1 score metric for Keras.\n",
        "Implements F1 score calculation directly in TensorFlow for use during training.\n",
        "\"\"\"\n",
        "@register_keras_serializable()\n",
        "def f1_metric(y_true, y_pred):\n",
        "    y_pred_binary = tf.cast(tf.greater(y_pred, 0.5), tf.float32)\n",
        "\n",
        "    true_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred_binary, 1)), tf.float32))\n",
        "    false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred_binary, 1)), tf.float32))\n",
        "    false_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred_binary, 0)), tf.float32))\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives + tf.keras.backend.epsilon())\n",
        "    recall = true_positives / (true_positives + false_negatives + tf.keras.backend.epsilon())\n",
        "\n",
        "    f1 = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b7d6e9",
      "metadata": {
        "id": "32b7d6e9"
      },
      "source": [
        "# Prediction Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cbe887ce",
      "metadata": {
        "id": "cbe887ce"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Threshold-based prediction function that ensures at least one emotion is predicted.\n",
        "Addresses the requirement to prevent all-zero predictions.\n",
        "Based on the principles discussed in Lipton et al., 2014 [5] with our adaptation\n",
        "for multi-label classification.\n",
        "\"\"\"\n",
        "def predict_with_threshold(model, X, threshold=0.5):\n",
        "    y_pred_proba = model.predict(X)\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    # If any row has all zeros, set the highest probability class to 1\n",
        "    zero_rows = np.where(np.sum(y_pred, axis=1) == 0)[0]\n",
        "    for row in zero_rows:\n",
        "        max_prob_idx = np.argmax(y_pred_proba[row])\n",
        "        y_pred[row, max_prob_idx] = 1\n",
        "\n",
        "    return y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c82180",
      "metadata": {
        "id": "72c82180"
      },
      "source": [
        "# Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5b59fca6",
      "metadata": {
        "id": "5b59fca6"
      },
      "outputs": [],
      "source": [
        "@register_keras_serializable()\n",
        "class LearnablePositionalEncoding(layers.Layer):\n",
        "    def __init__(self, maxlen, embedding_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.pos_embedding = self.add_weight(\n",
        "            shape=(maxlen, embedding_dim),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name=\"learnable_pos_embedding\"\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        # x shape: (batch_size, sequence_length, embedding_dim)\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        return x + self.pos_embedding[tf.newaxis, :seq_len, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e188d2a8",
      "metadata": {
        "id": "e188d2a8"
      },
      "outputs": [],
      "source": [
        "#model with learnable positional encoding\n",
        "def build_transformer_model(vocab_size, embedding_dim=100, num_heads=8, ff_dim=128, dropout_rate=0.1):\n",
        "    inputs = Input(shape=(max_len,))\n",
        "\n",
        "    # Embedding + positional encoding\n",
        "    x = Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    x = LearnablePositionalEncoding(maxlen=max_len, embedding_dim=embedding_dim)(x)\n",
        "\n",
        "    # Transformer block\n",
        "    attention_output = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embedding_dim // num_heads\n",
        "    )(x, x)\n",
        "\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention_output + x)\n",
        "\n",
        "    # Feed Forward\n",
        "    ff = Dense(ff_dim, activation='relu')(x)\n",
        "    ff = Dense(embedding_dim)(ff)\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
        "\n",
        "    # Classification head\n",
        "    x = GlobalMaxPooling1D()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    outputs = Dense(len(emotion_columns), activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss=focal_loss_with_penalty,\n",
        "        metrics=['accuracy', f1_metric]\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03824b91",
      "metadata": {
        "id": "03824b91"
      },
      "source": [
        "# callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8ac3007c",
      "metadata": {
        "id": "8ac3007c"
      },
      "outputs": [],
      "source": [
        "# Set up callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_f1_metric', patience=4, mode='max', restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.h5', monitor='val_f1_metric', mode='max', save_best_only=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "91a0e009",
      "metadata": {
        "id": "91a0e009"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, model_name):\n",
        "    print(f\"\\n=== Training {model_name} ===\")\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_pad, y_train,\n",
        "        epochs=10,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    y_pred = predict_with_threshold(model, X_test_pad, threshold=0.5)\n",
        "\n",
        "    # Calculate F1 scores\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
        "    weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
        "    print(f\"Micro F1 Score: {micro_f1:.4f}\")\n",
        "    print(f\"Weighted F1 Score: {weighted_f1:.4f}\")\n",
        "\n",
        "    # Check if any all-zero predictions remain\n",
        "    zero_preds = (np.sum(y_pred, axis=1) == 0).sum()\n",
        "    print(f\"Texts with no emotion predictions: {zero_preds} ({zero_preds/len(y_test)*100:.2f}%)\")\n",
        "\n",
        "\n",
        "    return model, macro_f1, micro_f1, weighted_f1, y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "aa750b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aa750b54",
        "outputId": "a5dcf560-fd56-40b6-d04d-3dd715b7a335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Building Transformer model...\n",
            "WARNING:tensorflow:From c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ learnable_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,000</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LearnablePosition…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span> │ learnable_positi… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ learnable_positi… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "│                     │                   │            │ learnable_positi… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,856</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,196</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │  \u001b[38;5;34m1,000,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ learnable_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │     \u001b[38;5;34m10,000\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mLearnablePosition…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │     \u001b[38;5;34m38,788\u001b[0m │ learnable_positi… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ learnable_positi… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "│                     │                   │            │ learnable_positi… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │        \u001b[38;5;34m200\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m12,928\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │     \u001b[38;5;34m12,900\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │        \u001b[38;5;34m200\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m25,856\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │      \u001b[38;5;34m7,196\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,108,068</span> (4.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,108,068\u001b[0m (4.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,108,068</span> (4.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,108,068\u001b[0m (4.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training Transformer ===\n",
            "Epoch 1/10\n",
            "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2162 - f1_metric: 0.0487 - loss: 0.0131"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 46ms/step - accuracy: 0.2163 - f1_metric: 0.0487 - loss: 0.0131 - val_accuracy: 0.3571 - val_f1_metric: 0.2070 - val_loss: 0.0135\n",
            "Epoch 2/10\n",
            "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3597 - f1_metric: 0.1883 - loss: 0.0101"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.3597 - f1_metric: 0.1883 - loss: 0.0101 - val_accuracy: 0.3884 - val_f1_metric: 0.3182 - val_loss: 0.0130\n",
            "Epoch 3/10\n",
            "\u001b[1m 999/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3872 - f1_metric: 0.2902 - loss: 0.0097"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - accuracy: 0.3872 - f1_metric: 0.2902 - loss: 0.0097 - val_accuracy: 0.3915 - val_f1_metric: 0.3369 - val_loss: 0.0130\n",
            "Epoch 4/10\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.4155 - f1_metric: 0.3483 - loss: 0.0094 - val_accuracy: 0.3814 - val_f1_metric: 0.3340 - val_loss: 0.0130\n",
            "Epoch 5/10\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 23ms/step - accuracy: 0.4497 - f1_metric: 0.3996 - loss: 0.0092 - val_accuracy: 0.3639 - val_f1_metric: 0.3343 - val_loss: 0.0132\n",
            "Epoch 6/10\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.4900 - f1_metric: 0.4547 - loss: 0.0089 - val_accuracy: 0.3549 - val_f1_metric: 0.3350 - val_loss: 0.0134\n",
            "Epoch 7/10\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 42ms/step - accuracy: 0.5324 - f1_metric: 0.5127 - loss: 0.0086 - val_accuracy: 0.3417 - val_f1_metric: 0.3339 - val_loss: 0.0137\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "\n",
            "Transformer Results:\n",
            "Macro F1 Score: 0.2307\n",
            "Micro F1 Score: 0.3911\n",
            "Weighted F1 Score: 0.3190\n",
            "Texts with no emotion predictions: 0 (0.00%)\n"
          ]
        }
      ],
      "source": [
        "# Initialize and train Transformer model\n",
        "print(\"\\nBuilding Transformer model...\")\n",
        "transformer_model = build_transformer_model(vocab_size=min(len(tokenizer.word_index) + 1, max_words))\n",
        "transformer_model.summary()\n",
        "transformer_model, transformer_macro_f1, transformer_micro_f1, transformer_weighted_f1, transformer_preds = train_and_evaluate(transformer_model, \"Transformer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcf9c0d3",
      "metadata": {
        "id": "fcf9c0d3"
      },
      "source": [
        "# optimize threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "71e7f2b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71e7f2b0",
        "outputId": "c754f169-701d-45a5-ae5f-4eab647c9dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optimizing threshold for best model...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "Threshold: 0.20, Micro F1: 0.0812\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
            "Threshold: 0.25, Micro F1: 0.0976\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step\n",
            "Threshold: 0.30, Micro F1: 0.1967\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "Threshold: 0.35, Micro F1: 0.3233\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "Threshold: 0.40, Micro F1: 0.3926\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Threshold: 0.45, Micro F1: 0.3990\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Threshold: 0.50, Micro F1: 0.3911\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Threshold: 0.55, Micro F1: 0.3868\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "Threshold: 0.60, Micro F1: 0.3860\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Threshold: 0.65, Micro F1: 0.3857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "Threshold: 0.70, Micro F1: 0.3857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Threshold: 0.75, Micro F1: 0.3857\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
            "Threshold: 0.80, Micro F1: 0.3857\n",
            "\n",
            "Best threshold: 0.45\n",
            "Best F1 score: 0.3990\n"
          ]
        }
      ],
      "source": [
        "def optimize_threshold(model, X, y_true, thresholds=None):\n",
        "    if thresholds is None:\n",
        "        thresholds = np.arange(0.2, 0.8, 0.05)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred = predict_with_threshold(model, X, threshold=threshold)\n",
        "        micro_f1 = f1_score(y_true, y_pred, average='micro')\n",
        "        results.append((threshold, micro_f1))\n",
        "        print(f\"Threshold: {threshold:.2f}, Micro F1: {micro_f1:.4f}\")\n",
        "\n",
        "    best_threshold, best_f1 = max(results, key=lambda x: x[1])\n",
        "    print(f\"\\nBest threshold: {best_threshold:.2f}\")\n",
        "    print(f\"Best F1 score: {best_f1:.4f}\")\n",
        "\n",
        "    return best_threshold\n",
        "\n",
        "\"\"\"\n",
        "Threshold Optimization and Final Evaluation\n",
        "\"\"\"\n",
        "# Optimize threshold for best model\n",
        "print(\"\\nOptimizing threshold for best model...\")\n",
        "best_threshold = optimize_threshold(transformer_model, X_test_pad, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6bbdb9b",
      "metadata": {
        "id": "e6bbdb9b"
      },
      "source": [
        "# Saving the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bd4c4ddf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "bd4c4ddf",
        "outputId": "25da2456-dccf-4e22-fb27-1ce8ff85a126"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "# Load the original word index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Shift indices by 3 to reserve special tokens\n",
        "word_index = {word: (index + 3) for word, index in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "transformer_model.save(\"emotion_model.keras\")\n",
        "model_bin.save(\"sentiment_model.keras\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Save tokenizer\n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "# Save word_index and emotion_columns if used explicitly\n",
        "with open(\"assets.pkl\", \"wb\") as f:\n",
        "    pickle.dump({'word_index': word_index, 'emotion_columns': emotion_columns, 'best_threshold': best_threshold}, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c9733d2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "63a5f67a",
      "metadata": {},
      "source": [
        "# Audio Streaming "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2bfc72b5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Recording started — press Ctrl+C to stop\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-15 (process_audio):\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"C:\\Users\\franc\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
            "    _threading_Thread_run(self)\n",
            "  File \"c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_16572\\1715734442.py\", line 43, in process_audio\n",
            "  File \"c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 814, in __call__\n",
            "    raise ValueError(\n",
            "ValueError: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: Okay. Okay. (of type <class 'str'>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribed: Okay. Okay.\n",
            "\n",
            "* Recording stopped\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import numpy as np\n",
        "import queue\n",
        "import threading\n",
        "import pyaudio\n",
        "import time\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Initialize the Whisper model\n",
        "whisper_model = whisper.load_model(\"base\") \n",
        "\n",
        "CHUNK = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "CHANNELS = 1\n",
        "RATE = 16000\n",
        "RECORD_SECONDS = 3\n",
        "\n",
        "p = pyaudio.PyAudio()\n",
        "audio_queue = queue.Queue()\n",
        "\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                frames_per_buffer=CHUNK)\n",
        "\n",
        "\n",
        "def process_audio():\n",
        "    while True:\n",
        "        audio_data = audio_queue.get()\n",
        "        # to float32 in range [-1,1]\n",
        "        audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0\n",
        "\n",
        "        # Whisper transcription\n",
        "        result = whisper_model.transcribe(audio_np, fp16=False)\n",
        "        text = result[\"text\"].strip()\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        print(f\"Transcribed: {text}\")\n",
        "\n",
        "        # Sentiment\n",
        "        sentiment = model_bin(text)\n",
        "        print(f\"Sentiment: {sentiment}\")\n",
        "\n",
        "        # Emotions\n",
        "        emotions = transformer_model([text])[0]\n",
        "        print(f\"Emotions: {emotions}\")\n",
        "\n",
        "# start background thread\n",
        "threading.Thread(target=process_audio, daemon=True).start()\n",
        "\n",
        "\n",
        "try:\n",
        "    print(\"* Recording started — press Ctrl+C to stop\")\n",
        "    while True:\n",
        "        frames = []\n",
        "        for _ in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "            data = stream.read(CHUNK, exception_on_overflow=False)\n",
        "            frames.append(data)\n",
        "        audio_queue.put(b\"\".join(frames))\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n* Recording stopped\")\n",
        "\n",
        "finally:\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    p.terminate()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

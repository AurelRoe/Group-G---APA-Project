{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vWWe-ZpUDO0"
      },
      "source": [
        "# Setting up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CslG8VIzUCpy",
        "outputId": "710d6cc1-b2ba-4d64-f5a1-2c45b0c81246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Collecting openai\n",
            "  Downloading openai-1.82.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.82.0-py3-none-any.whl (720 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, openai, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.78.1\n",
            "    Uninstalling openai-1.78.1:\n",
            "      Successfully uninstalled openai-1.78.1\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 openai-1.82.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain langchain-community openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yoqx_UcKT5ey"
      },
      "source": [
        "# Loading the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSXkAFAiTY3a",
        "outputId": "b956fd89-3c6c-40da-b77b-81b0ee09142a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            " assets.pkl\t        emotions_model.keras   __pycache__\n",
            " Combined_model.ipynb   emotion_utils.py       sentiment_model.keras\n",
            " custom_funtions.py     labels_2.csv\t       tokenizer.pkl\n",
            "'Demo Diary.ipynb'      mood_diary.csv\t       Try_using_function.ipynb\n"
          ]
        }
      ],
      "source": [
        "#Only needed when using Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(r\"/content/drive/My Drive/Colab Notebooks/Predictive Analytics/Francisco/Combined model\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLDgx46jTvOz",
        "outputId": "b6adf5bd-f1d3-4ae9-b9ed-13aee8b9540a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 24 variables whereas the saved optimizer has 46 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 9 variables whereas the saved optimizer has 16 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959ms/step\n",
            "[['Positive', ['sadness']]]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from keras.datasets import imdb\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import load_model\n",
        "from emotion_utils import predict_sent_emotions\n",
        "from custom_funtions import LearnablePositionalEncoding, focal_loss_with_penalty, f1_metric\n",
        "\n",
        "\n",
        "model = load_model(\"emotions_model.keras\", custom_objects={\n",
        "    \"LearnablePositionalEncoding\": LearnablePositionalEncoding,\n",
        "    \"focal_loss_with_penalty\": focal_loss_with_penalty,\n",
        "    \"f1_metric\": f1_metric\n",
        "})\n",
        "\n",
        "# Load models\n",
        "model_emotion = load_model(\"emotions_model.keras\", custom_objects={\n",
        "    \"LearnablePositionalEncoding\": LearnablePositionalEncoding,\n",
        "    \"focal_loss_with_penalty\": focal_loss_with_penalty,\n",
        "    \"f1_metric\": f1_metric\n",
        "})\n",
        "\n",
        "model_sentiment = load_model(\"sentiment_model.keras\")\n",
        "\n",
        "# Load tokenizer and other assets\n",
        "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "with open(\"assets.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "    word_index = data['word_index']\n",
        "    emotion_columns = data['emotion_columns']\n",
        "\n",
        "# Predict\n",
        "text = \"I cried during the whole movie of sadness, but it was really good\"\n",
        "result = predict_sent_emotions(text, model_emotion, model_sentiment, tokenizer,\n",
        "                               word_index, emotion_columns, max_len=100, threshold=0.5)\n",
        "\n",
        "print(result)\n",
        "# Output: ['Positive', ['Joy', 'Excitement']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yr7R4Sia04n"
      },
      "source": [
        "# Connect to Claude API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v0wXXfENbC_w"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IWXzxDX6bXjg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeKy6tNabbXi",
        "outputId": "14fb101f-8a57-47f5-8d3b-61e2f335d134"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unmatched ')' (391973923.py, line 10)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
          ]
        }
      ],
      "source": [
        "# Install Anthropics SDK\n",
        "!pip install anthropic\n",
        "\n",
        "import anthropic\n",
        "import os\n",
        "\n",
        "# Set API key\n",
        "#client = anthropic.Anthropic(\n",
        "    #api_key= \"IN THE REPORT\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK1eusL0FW_y"
      },
      "source": [
        "## Getting the data from the audio files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "h5N3c4KZFaa3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data from CSV\n",
        "input_data = pd.read_csv('labels_2.csv')\n",
        "\n",
        "# Extract only the first column\n",
        "input_data_text = input_data.iloc[:, 3]\n",
        "input_data_sentiment = input_data.iloc[:, 1]\n",
        "input_data_emotion = input_data.iloc[:, 2]\n",
        "\n",
        "# Convert the first column to a list\n",
        "input_data_text = input_data_text.tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtLdE273WTFj"
      },
      "source": [
        "# Comparing own model with claude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKoQrHyWgJnX",
        "outputId": "b4559a7c-c1b5-40bf-e64a-aeb01200bd13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Sentiment Analysis with our own model ===\n",
            "\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Emotion Accuracy: 13.17%\n",
            "Sentiment Accuracy: 65.37%\n"
          ]
        }
      ],
      "source": [
        "# List of test sentences\n",
        "example_texts = [\n",
        "    \"The movie was fantastic! I loved every second.\",\n",
        "    \"What a terrible film. I walked out halfway.\",\n",
        "    \"It was okay, not great but not bad either.\",\n",
        "    \"I cried through the whole thing, it was so emotional.\",\n",
        "    \"I'm still laughing! That was hilarious.\"\n",
        "]\n",
        "\n",
        "# Prompt template for binary sentiment classification\n",
        "def binary_classification_prompt(text):\n",
        "    return f\"\"\"Classify the sentiment of the following sentence as Positive or Negative. Just answer with one word: Positive or Negative.\\n\\n{text}\"\"\"\n",
        "\n",
        "# Prompt template for multi-class emotion detection\n",
        "def multi_class_emotion_prompt(text):\n",
        "    return f\"\"\"Classify the sentiment of the following sentence as the suitable emotions out of the following list: admiration, amusement, anger, annoyance,\n",
        "               approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy,\n",
        "                love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral.\n",
        "                Just answer with the list of all detected emotions and nothing else.\\n\\n{text}\"\"\"\n",
        "\n",
        "\n",
        "#Our own model\n",
        "print(\"\\n=== Sentiment Analysis with our own model ===\\n\")\n",
        "predictions = predict_sent_emotions(input_data_text, model_emotion, model_sentiment, tokenizer,\n",
        "                               word_index, emotion_columns, max_len=100, threshold=0.5)\n",
        "\n",
        "#accuracy of sentiment\n",
        "sentiments_pred = [prediction[0] for prediction in predictions]\n",
        "sentiments_true = input_data_sentiment.tolist()\n",
        "correct_sentiments = sum(\n",
        "    1 for pred, true in zip(sentiments_pred, sentiments_true) if pred.lower() == true.lower()\n",
        ")\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_sentiment = correct_sentiments / len(sentiments_true)\n",
        "\n",
        "#accuracy for emotion\n",
        "emotions_pred = [prediction[1] for prediction in predictions]\n",
        "emotions_true = input_data_emotion.tolist()\n",
        "correct_emotions = sum(\n",
        "    1 for pred_list, true in zip(emotions_pred, emotions_true)\n",
        "    if any(p.lower() == true.lower() for p in pred_list)\n",
        ")\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_emotions = correct_emotions / len(emotions_true)\n",
        "\n",
        "print(f\"Emotion Accuracy: {accuracy_emotions:.2%}\")\n",
        "print(f\"Sentiment Accuracy: {accuracy_sentiment:.2%}\")\n",
        "\n",
        "#get the emotions that are predicted as 1\n",
        "#predicted_emotions = predictions.loc[:, (predictions != 0).any(axis=0)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5UTygSTH0H1",
        "outputId": "b32fea41-8bc1-4313-c384-e452c16ecff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Sentiment Analysis with Claude ===\n",
            "\n",
            "Emotion Accuracy: 86.34%\n",
            "Sentiment Accuracy: 96.59%\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "correct_emotions = 0\n",
        "correct_sentiments = 0\n",
        "\n",
        "print(\"\\n=== Sentiment Analysis with Claude ===\\n\")\n",
        "# Run Claude over the list\n",
        "for i, text in enumerate(input_data_text):\n",
        "    # First call: Binary classification\n",
        "    binary_response = client.messages.create(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        max_tokens=20,\n",
        "        messages=[{\"role\": \"user\", \"content\": binary_classification_prompt(text)}]\n",
        "    )\n",
        "    binary_prediction = binary_response.content[0].text.strip()\n",
        "    binary_prediction = binary_prediction.strip().lower().rstrip(string.punctuation)\n",
        "    if binary_prediction == input_data_sentiment[i].lower():\n",
        "      correct_sentiments += 1\n",
        "\n",
        "    # Second call: Emotion detection\n",
        "    emotion_response = client.messages.create(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        max_tokens=100,\n",
        "        messages=[{\"role\": \"user\", \"content\": multi_class_emotion_prompt(text)}]\n",
        "    )\n",
        "    emotion_prediction = emotion_response.content[0].text.strip()\n",
        "\n",
        "    predicted_emotions = [\n",
        "        e.strip().lower().rstrip(string.punctuation)\n",
        "        for e in emotion_prediction.split(',')\n",
        "    ]\n",
        "\n",
        "    # Normalize true emotion\n",
        "    true_emotion = input_data_emotion[i].strip().lower().rstrip(string.punctuation)\n",
        "\n",
        "    if true_emotion in predicted_emotions:\n",
        "        correct_emotions += 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_sentiment = correct_sentiments / len(sentiments_true)\n",
        "accuracy_emotions = correct_emotions / len(emotions_true)\n",
        "\n",
        "print(f\"Emotion Accuracy: {accuracy_emotions:.2%}\")\n",
        "print(f\"Sentiment Accuracy: {accuracy_sentiment:.2%}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2vWWe-ZpUDO0"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
